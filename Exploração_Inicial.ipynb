{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ramon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import tokenize\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import unidecode\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_original = pd.read_csv(\"./datasets/movies_amostra.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_original)\n",
    "dataset = dataset_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   False\n",
       "titulo               False\n",
       "adulto               False\n",
       "orcamento            False\n",
       "idioma_original       True\n",
       "popularidade         False\n",
       "data_de_estreia      False\n",
       "resumo                True\n",
       "receita              False\n",
       "duracao               True\n",
       "genero               False\n",
       "ator_1                True\n",
       "ator_2                True\n",
       "ator_3                True\n",
       "ator_4                True\n",
       "ator_5                True\n",
       "dirigido_por          True\n",
       "escrito_por_1         True\n",
       "escrito_por_2         True\n",
       "historia_original     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'titulo', 'adulto', 'orcamento', 'idioma_original',\n",
       "       'popularidade', 'data_de_estreia', 'resumo', 'receita', 'duracao',\n",
       "       'genero', 'ator_1', 'ator_2', 'ator_3', 'ator_4', 'ator_5',\n",
       "       'dirigido_por', 'escrito_por_1', 'escrito_por_2', 'historia_original'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_original.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    2132\n",
       "fr     152\n",
       "it     128\n",
       "ja      98\n",
       "cn      65\n",
       "ru      55\n",
       "es      54\n",
       "de      51\n",
       "zh      44\n",
       "hi      39\n",
       "sv      27\n",
       "ko      25\n",
       "fi      22\n",
       "pl      14\n",
       "nl      11\n",
       "tr      10\n",
       "da      10\n",
       "pt      10\n",
       "ta       8\n",
       "th       6\n",
       "no       5\n",
       "hu       4\n",
       "el       4\n",
       "sr       4\n",
       "ml       4\n",
       "ro       3\n",
       "te       2\n",
       "cs       2\n",
       "he       2\n",
       "lb       1\n",
       "uk       1\n",
       "et       1\n",
       "ur       1\n",
       "xx       1\n",
       "mr       1\n",
       "fa       1\n",
       "id       1\n",
       "Name: idioma_original, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_original[\"idioma_original\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop([\"idioma_original\", \"data_de_estreia\", \"historia_original\", \"duracao\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>titulo</th>\n",
       "      <th>adulto</th>\n",
       "      <th>orcamento</th>\n",
       "      <th>popularidade</th>\n",
       "      <th>resumo</th>\n",
       "      <th>receita</th>\n",
       "      <th>genero</th>\n",
       "      <th>ator_1</th>\n",
       "      <th>ator_2</th>\n",
       "      <th>ator_3</th>\n",
       "      <th>ator_4</th>\n",
       "      <th>ator_5</th>\n",
       "      <th>dirigido_por</th>\n",
       "      <th>escrito_por_1</th>\n",
       "      <th>escrito_por_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86295</td>\n",
       "      <td>Treasure of the Yankee Zephyr</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>In a lake high in the mountains of New Zealand...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Action</td>\n",
       "      <td>Ken Wahl</td>\n",
       "      <td>Lesley Ann Warren</td>\n",
       "      <td>Donald Pleasence</td>\n",
       "      <td>George Peppard</td>\n",
       "      <td>Bruno Lawrence</td>\n",
       "      <td>David Hemmings</td>\n",
       "      <td>Everett De Roche</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289198</td>\n",
       "      <td>Redeemer</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A former hit-man for a drug cartel becomes a v...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Action</td>\n",
       "      <td>Marko Zaror</td>\n",
       "      <td>Loreto Aravena</td>\n",
       "      <td>Mauricio Diocares</td>\n",
       "      <td>José Luís Mósca</td>\n",
       "      <td>Noah Segan</td>\n",
       "      <td>Ernesto Díaz Espinoza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24382</td>\n",
       "      <td>Big Deal on Madonna Street</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Peppe, formerly a boxer, organizes the break-i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Vittorio Gassman</td>\n",
       "      <td>Renato Salvatori</td>\n",
       "      <td>Memmo Carotenuto</td>\n",
       "      <td>Rossana Rory</td>\n",
       "      <td>Carla Gravina</td>\n",
       "      <td>Mario Monicelli</td>\n",
       "      <td>Agenore Incrocci</td>\n",
       "      <td>Furio Scarpelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>479</td>\n",
       "      <td>Shaft</td>\n",
       "      <td>False</td>\n",
       "      <td>46000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>New York police detective John Shaft arrests W...</td>\n",
       "      <td>107196498.0</td>\n",
       "      <td>Action</td>\n",
       "      <td>Samuel L. Jackson</td>\n",
       "      <td>Jeffrey Wright</td>\n",
       "      <td>Christian Bale</td>\n",
       "      <td>Busta Rhymes</td>\n",
       "      <td>Dan Hedaya</td>\n",
       "      <td>John Singleton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37712</td>\n",
       "      <td>Pistol Opera</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>As one of Suzuki's last fims, it is related to...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Action</td>\n",
       "      <td>Makiko Esumi</td>\n",
       "      <td>Sayoko Yamaguchi</td>\n",
       "      <td>Hanae Kan</td>\n",
       "      <td>Masatoshi Nagase</td>\n",
       "      <td>Mikijiro Hira</td>\n",
       "      <td>Seijun Suzuki</td>\n",
       "      <td>Kazunori Ito</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                         titulo  adulto  orcamento  popularidade  \\\n",
       "0   86295  Treasure of the Yankee Zephyr   False          0           2.0   \n",
       "1  289198                       Redeemer   False          0           2.0   \n",
       "2   24382     Big Deal on Madonna Street   False          0          11.0   \n",
       "3     479                          Shaft   False   46000000          13.0   \n",
       "4   37712                   Pistol Opera   False          0           2.0   \n",
       "\n",
       "                                              resumo      receita  genero  \\\n",
       "0  In a lake high in the mountains of New Zealand...          0.0  Action   \n",
       "1  A former hit-man for a drug cartel becomes a v...          0.0  Action   \n",
       "2  Peppe, formerly a boxer, organizes the break-i...          0.0  Comedy   \n",
       "3  New York police detective John Shaft arrests W...  107196498.0  Action   \n",
       "4  As one of Suzuki's last fims, it is related to...          0.0  Action   \n",
       "\n",
       "              ator_1             ator_2             ator_3            ator_4  \\\n",
       "0           Ken Wahl  Lesley Ann Warren   Donald Pleasence    George Peppard   \n",
       "1        Marko Zaror     Loreto Aravena  Mauricio Diocares   José Luís Mósca   \n",
       "2   Vittorio Gassman   Renato Salvatori   Memmo Carotenuto      Rossana Rory   \n",
       "3  Samuel L. Jackson     Jeffrey Wright     Christian Bale      Busta Rhymes   \n",
       "4       Makiko Esumi   Sayoko Yamaguchi          Hanae Kan  Masatoshi Nagase   \n",
       "\n",
       "           ator_5           dirigido_por     escrito_por_1    escrito_por_2  \n",
       "0  Bruno Lawrence         David Hemmings  Everett De Roche              NaN  \n",
       "1      Noah Segan  Ernesto Díaz Espinoza               NaN              NaN  \n",
       "2   Carla Gravina        Mario Monicelli  Agenore Incrocci  Furio Scarpelli  \n",
       "3      Dan Hedaya         John Singleton               NaN              NaN  \n",
       "4   Mikijiro Hira          Seijun Suzuki      Kazunori Ito              NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"classificacao\"] = dataset[\"genero\"].replace([\"Action\", \"Comedy\"],[0, 1])\n",
    "dataset.drop(0, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1988\n",
      "0    1012\n",
      "Name: classificacao, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"classificacao\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"resumo\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset['resumo'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"resumo\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumos = dataset[\"resumo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.fillna(\"nenhum\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14655\n",
      "9503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ramon\\anaconda3\\envs\\mlcefet\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "todos_atores = np.array(dataset[[\"ator_1\", \"ator_2\", \"ator_3\", \"ator_4\", \"ator_5\"]]).reshape(-1, 1)\n",
    "print(len(todos_atores))\n",
    "print(len(np.unique(todos_atores)))\n",
    "label_atores = LabelEncoder().fit(todos_atores)\n",
    "cat_atores = label_atores.transform(todos_atores)\n",
    "encoded_atores = list()\n",
    "for index, row in dataset.iterrows():\n",
    "    labels_row = label_atores.transform([row['ator_1'], row['ator_2'], row['ator_3'], row['ator_4'], row['ator_5']])\n",
    "    zeros = np.zeros(len(np.unique(todos_atores)))\n",
    "    zeros[labels_row] = 1\n",
    "    encoded_atores.append(zeros)\n",
    "dataset[\"atores_encoded\"] = encoded_atores\n",
    "dataset.drop([\"ator_1\", \"ator_2\", \"ator_3\", \"ator_4\", \"ator_5\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dirigido = LabelEncoder().fit(dataset[\"dirigido_por\"])\n",
    "labelled_dirigido = label_dirigido.transform(dataset[\"dirigido_por\"]).reshape(-1, 1)\n",
    "onehot_dirigido = OneHotEncoder(sparse=False).fit(labelled_dirigido)\n",
    "onehotted_dirigido = onehot_dirigido.transform(labelled_dirigido)\n",
    "dataset[\"dirigido_encoded\"] = onehotted_dirigido.tolist()\n",
    "dataset.drop(\"dirigido_por\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5862\n",
      "1424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ramon\\anaconda3\\envs\\mlcefet\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "todos_escritores = np.array(dataset[[\"escrito_por_1\", \"escrito_por_2\"]]).reshape(-1, 1)\n",
    "print(len(todos_escritores))\n",
    "print(len(np.unique(todos_escritores)))\n",
    "label_escritores = LabelEncoder().fit(todos_escritores)\n",
    "cat_escritores = label_escritores.transform(todos_escritores)\n",
    "encoded_escritores = list()\n",
    "for index, row in dataset.iterrows():\n",
    "    labels_row = label_escritores.transform([row['escrito_por_1'], row['escrito_por_2']])\n",
    "    zeros = np.zeros(len(np.unique(todos_escritores)))\n",
    "    zeros[labels_row] = 1\n",
    "    encoded_escritores.append(zeros)\n",
    "dataset[\"escritores_encoded\"] = encoded_escritores\n",
    "dataset.drop([\"escrito_por_1\", \"escrito_por_2\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "escalados = StandardScaler().fit_transform(dataset[[\"receita\", \"popularidade\", \"orcamento\"]])\n",
    "dataset[\"receita_scaled\"] = escalados[:, 0]\n",
    "dataset[\"popularidade_scaled\"] = escalados[:, 1]\n",
    "dataset[\"orcamento_scaled\"] = escalados[:, 2]\n",
    "dataset.drop([\"receita\", \"orcamento\", \"popularidade\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tratamento do texto\n",
    "pontuacao = [i for i in punctuation]\n",
    "tokenizer_pontuacao = tokenize.WordPunctTokenizer()\n",
    "pontuacao_stopwords = pontuacao + nltk.corpus.stopwords.words(\"english\")\n",
    "stopwords_sem_acento = [unidecode.unidecode(texto) for texto in pontuacao_stopwords]\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "dataset[\"resumo_tratado\"] = [unidecode.unidecode(texto) for texto in dataset[\"resumo\"]]\n",
    "frase_processada = list()\n",
    "for resumo in dataset[\"resumo_tratado\"]:\n",
    "    nova_frase = list()\n",
    "    resumo = resumo.lower()\n",
    "    palavras_texto = tokenizer_pontuacao.tokenize(resumo)\n",
    "    for palavra in palavras_texto:\n",
    "        if palavra not in stopwords_sem_acento:\n",
    "            nova_frase.append(stemmer.stem(palavra))\n",
    "    frase_processada.append(' '.join(nova_frase))\n",
    "dataset[\"resumo_tratado\"] = frase_processada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vetorizar = TfidfVectorizer(lowercase=False)\n",
    "bag_of_words = vetorizar.fit_transform(dataset[\"resumo_tratado\"])\n",
    "dataset[\"bag_of_words\"] = bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>titulo</th>\n",
       "      <th>adulto</th>\n",
       "      <th>resumo</th>\n",
       "      <th>classificacao</th>\n",
       "      <th>atores_encoded</th>\n",
       "      <th>dirigido_encoded</th>\n",
       "      <th>escritores_encoded</th>\n",
       "      <th>receita_scaled</th>\n",
       "      <th>popularidade_scaled</th>\n",
       "      <th>orcamento_scaled</th>\n",
       "      <th>resumo_tratado</th>\n",
       "      <th>bag_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86295</td>\n",
       "      <td>Treasure of the Yankee Zephyr</td>\n",
       "      <td>False</td>\n",
       "      <td>In a lake high in the mountains of New Zealand...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>-0.240121</td>\n",
       "      <td>-0.432328</td>\n",
       "      <td>-0.308391</td>\n",
       "      <td>lake high mountain new zealand hunter gibbi gi...</td>\n",
       "      <td>(0, 12245)\\t0.2137935761906109\\n  (0, 7150)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289198</td>\n",
       "      <td>Redeemer</td>\n",
       "      <td>False</td>\n",
       "      <td>A former hit-man for a drug cartel becomes a v...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>-0.240121</td>\n",
       "      <td>-0.432328</td>\n",
       "      <td>-0.308391</td>\n",
       "      <td>former hit man drug cartel becom vigilant pay ...</td>\n",
       "      <td>(0, 12245)\\t0.2137935761906109\\n  (0, 7150)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24382</td>\n",
       "      <td>Big Deal on Madonna Street</td>\n",
       "      <td>False</td>\n",
       "      <td>Peppe, formerly a boxer, organizes the break-i...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>-0.240121</td>\n",
       "      <td>0.496670</td>\n",
       "      <td>-0.308391</td>\n",
       "      <td>pepp former boxer organ break pawnshop tiberio...</td>\n",
       "      <td>(0, 12245)\\t0.2137935761906109\\n  (0, 7150)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>479</td>\n",
       "      <td>Shaft</td>\n",
       "      <td>False</td>\n",
       "      <td>New York police detective John Shaft arrests W...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.004307</td>\n",
       "      <td>0.703114</td>\n",
       "      <td>1.468008</td>\n",
       "      <td>new york polic detect john shaft arrest walter...</td>\n",
       "      <td>(0, 12245)\\t0.2137935761906109\\n  (0, 7150)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37712</td>\n",
       "      <td>Pistol Opera</td>\n",
       "      <td>False</td>\n",
       "      <td>As one of Suzuki's last fims, it is related to...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>-0.240121</td>\n",
       "      <td>-0.432328</td>\n",
       "      <td>-0.308391</td>\n",
       "      <td>one suzuki last fim relat 1967 brand kill eith...</td>\n",
       "      <td>(0, 12245)\\t0.2137935761906109\\n  (0, 7150)\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                         titulo  adulto  \\\n",
       "0   86295  Treasure of the Yankee Zephyr   False   \n",
       "1  289198                       Redeemer   False   \n",
       "2   24382     Big Deal on Madonna Street   False   \n",
       "3     479                          Shaft   False   \n",
       "4   37712                   Pistol Opera   False   \n",
       "\n",
       "                                              resumo  classificacao  \\\n",
       "0  In a lake high in the mountains of New Zealand...              0   \n",
       "1  A former hit-man for a drug cartel becomes a v...              0   \n",
       "2  Peppe, formerly a boxer, organizes the break-i...              1   \n",
       "3  New York police detective John Shaft arrests W...              0   \n",
       "4  As one of Suzuki's last fims, it is related to...              0   \n",
       "\n",
       "                                      atores_encoded  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                    dirigido_encoded  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                  escritores_encoded  receita_scaled  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...       -0.240121   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...       -0.240121   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...       -0.240121   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        1.004307   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...       -0.240121   \n",
       "\n",
       "   popularidade_scaled  orcamento_scaled  \\\n",
       "0            -0.432328         -0.308391   \n",
       "1            -0.432328         -0.308391   \n",
       "2             0.496670         -0.308391   \n",
       "3             0.703114          1.468008   \n",
       "4            -0.432328         -0.308391   \n",
       "\n",
       "                                      resumo_tratado  \\\n",
       "0  lake high mountain new zealand hunter gibbi gi...   \n",
       "1  former hit man drug cartel becom vigilant pay ...   \n",
       "2  pepp former boxer organ break pawnshop tiberio...   \n",
       "3  new york polic detect john shaft arrest walter...   \n",
       "4  one suzuki last fim relat 1967 brand kill eith...   \n",
       "\n",
       "                                        bag_of_words  \n",
       "0    (0, 12245)\\t0.2137935761906109\\n  (0, 7150)\\...  \n",
       "1    (0, 12245)\\t0.2137935761906109\\n  (0, 7150)\\...  \n",
       "2    (0, 12245)\\t0.2137935761906109\\n  (0, 7150)\\...  \n",
       "3    (0, 12245)\\t0.2137935761906109\\n  (0, 7150)\\...  \n",
       "4    (0, 12245)\\t0.2137935761906109\\n  (0, 7150)\\...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = dataset[[\"atores_encoded\", \"dirigido_encoded\", \n",
    "                      \"escritores_encoded\", \"receita_scaled\", \n",
    "                      \"popularidade_scaled\", \"orcamento_scaled\", \"bag_of_words\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = list()\n",
    "for index, row in inputs.iterrows():\n",
    "    model_input.append(np.hstack((row[\"atores_encoded\"], row[\"dirigido_encoded\"], row[\"escritores_encoded\"], row[\"receita_scaled\"], \n",
    "                      row[\"popularidade_scaled\"], row[\"orcamento_scaled\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressao Logistica 0.7353342428376535\n",
      "Random Forest 0.6807639836289222\n",
      "Rede Neural 0.7980900409276944\n"
     ]
    }
   ],
   "source": [
    "# Testando treinar com os parâmetros atores, diretor, escritores, receita, popularidade e orçamento\n",
    "treino, teste, classe_treino, classe_teste = train_test_split(model_input, dataset[\"classificacao\"], random_state=1)\n",
    "regressao_logistica = LogisticRegression(max_iter=1000)\n",
    "regressao_logistica.fit(treino, classe_treino)\n",
    "print(\"Regressao Logistica\", regressao_logistica.score(teste, classe_teste))\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(treino, classe_treino)\n",
    "print(\"Random Forest\", random_forest.score(teste, classe_teste))\n",
    "rede_neural = MLPClassifier()\n",
    "rede_neural.fit(treino, classe_treino)\n",
    "print(\"Rede Neural\", rede_neural.score(teste, classe_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressao Logistica 0.7517053206002728\n",
      "Random Forest 0.7680763983628922\n",
      "Rede Neural 0.7885402455661664\n"
     ]
    }
   ],
   "source": [
    "# Testando treinar apenas com o resumo\n",
    "treino, teste, classe_treino, classe_teste = train_test_split(bag_of_words, dataset[\"classificacao\"], random_state=1)\n",
    "regressao_logistica = LogisticRegression(max_iter=1000)\n",
    "regressao_logistica.fit(treino, classe_treino)\n",
    "print(\"Regressao Logistica\", regressao_logistica.score(teste, classe_teste))\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(treino, classe_treino)\n",
    "print(\"Random Forest\", random_forest.score(teste, classe_teste))\n",
    "rede_neural = MLPClassifier()\n",
    "rede_neural.fit(treino, classe_treino)\n",
    "print(\"Rede Neural\", rede_neural.score(teste, classe_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Expandir a bag of words ocupa memória demais, procurar outra forma de fazer isso\n",
    "# full_input = list()\n",
    "# for index, row in inputs.iterrows():\n",
    "#     full_input.append(np.hstack((row[\"atores_encoded\"], row[\"dirigido_encoded\"], row[\"escritores_encoded\"], row[\"receita_scaled\"], \n",
    "#                       row[\"popularidade_scaled\"], row[\"orcamento_scaled\"], row[\"bag_of_words\"].toarray().reshape(-1))))\n",
    "\n",
    "# #Testar treinar com todas as entradas\n",
    "# treino, teste, classe_treino, classe_teste = train_test_split(full_input, dataset[\"classificacao\"], random_state=1)\n",
    "# regressao_logistica = LogisticRegression(max_iter=1000)\n",
    "# regressao_logistica.fit(treino, classe_treino)\n",
    "# print(\"Regressao Logistica\", regressao_logistica.score(teste, classe_teste))\n",
    "# random_forest = RandomForestClassifier()\n",
    "# random_forest.fit(treino, classe_treino)\n",
    "# print(\"Random Forest\", random_forest.score(teste, classe_teste))\n",
    "# rede_neural = MLPClassifier()\n",
    "# rede_neural.fit(treino, classe_treino)\n",
    "# print(\"Rede Neural\", rede_neural.score(teste, classe_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
